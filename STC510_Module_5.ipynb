{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vhooker/stc510-mod-5-6/blob/main/STC510_Module_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Module 5: Look at Jeopardy words to determine the value of the questions.\n",
        "\n",
        "Steps- Combine Jeopardy answers and questions to gather all words.\n",
        "       Clean normalize words and remove punctuation.\n",
        "       convert values into high and low.\n"
      ],
      "metadata": {
        "id": "9kPoX1PQZdmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports and download tools for data cleaning"
      ],
      "metadata": {
        "id": "HBYh0xpEZ3fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import download\n"
      ],
      "metadata": {
        "id": "2n3ckf2xSo-3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download('stopwords')\n"
      ],
      "metadata": {
        "id": "-ulC-HuNSqx1",
        "outputId": "2aea49b6-5e82-407a-99b1-6bf954016d58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loadning JSON file"
      ],
      "metadata": {
        "id": "lING2uZEaEot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('jeopardy.json', 'r') as f:\n",
        "    jeopardydata = json.load(f)"
      ],
      "metadata": {
        "id": "wsWVP6ocSsru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make it a dataframe"
      ],
      "metadata": {
        "id": "pIrmR8eJaLna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jeop = pd.DataFrame(jeopardydata)\n"
      ],
      "metadata": {
        "id": "67BELN0hStML"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove unnecessary columns. We only have to"
      ],
      "metadata": {
        "id": "BUOo_2EIaRvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jeparody = jeop.drop(['category', 'air_date', 'round', 'show_number'], axis=1)"
      ],
      "metadata": {
        "id": "3chm1kmCSvsw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine questions and answer into new column- 'words'"
      ],
      "metadata": {
        "id": "FHNEbx9AdfR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jeparody['words'] = jeparody['question'] + jeparody['answer']"
      ],
      "metadata": {
        "id": "hoEKc6aRSyCh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the value column a float value-remove $ and convert."
      ],
      "metadata": {
        "id": "m8mKVD4RdofE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jeparody['value'] = jeparody['value'].str.replace('$', '')\n",
        "jeparody['value'] = pd.to_numeric(jeparody['value'], errors='coerce')"
      ],
      "metadata": {
        "id": "GTpem7HGS2wC",
        "outputId": "74bcb15e-aabf-4abc-9f13-67b59942a1a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-6a93b8ec3be1>:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  jeparody['value'] = jeparody['value'].str.replace('$', '')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove rows without values"
      ],
      "metadata": {
        "id": "whbucPFnXICI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jeparody = jeparody.dropna(subset=['value'])"
      ],
      "metadata": {
        "id": "a5cEe6UZS6Q0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the questions/answers. Makes the sentences into word lists.  "
      ],
      "metadata": {
        "id": "eSa_P0UmXPYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jeparody['clean words'] = jeparody['words'].apply(lambda x: word_tokenize(x.lower()))"
      ],
      "metadata": {
        "id": "GrB5wy_jS7q6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define stopwords"
      ],
      "metadata": {
        "id": "My3W9ShyXw1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_stopwords = set(stopwords.words('english') + ['~', ',', '.', '?', '!', '$', '&', ':', ';', '\"\"', \"''\", '@'])"
      ],
      "metadata": {
        "id": "V_XWcWysS9fO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove stopwords. This cleans the word list to avoid less important but frequent words (e.g. the, and) from skewing the resutls."
      ],
      "metadata": {
        "id": "MCj9NNyhX3c5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jeparody['stopped'] = jeparody['clean words'].apply(lambda x: [word for word in x if word not in english_stopwords])"
      ],
      "metadata": {
        "id": "N1NMHrs3S_Xi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lemmatization of the word lists to normalize the words (e.g tense)"
      ],
      "metadata": {
        "id": "0WgpADEZaTTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "jeparody['lemming'] = jeparody['stopped'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
      ],
      "metadata": {
        "id": "fivzK_loTB7M"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put the word lists into their own strings for processing"
      ],
      "metadata": {
        "id": "gLH09B76eVTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jeparody['finalform'] = jeparody['lemming'].apply(lambda x: ' '.join(x))"
      ],
      "metadata": {
        "id": "14K3302mTYld"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oh yeah! I initially forgot this the accuracy was not great with a full value spread. Convert the values into High (1) and low (0) sections. The values above 700 were high. I haven't watched Jeoparody in a while and with \"doubles\" and probably bonus rounds I figured I'd catch a majority of the high values and exclued the low values if I made the split 700 even if that left out the 400 and 500 options for the regular game play."
      ],
      "metadata": {
        "id": "okWrVZ9peifR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_high_value(x):\n",
        "    if x >= 700:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "jeparody['highval'] = jeparody['value'].apply(label_high_value)"
      ],
      "metadata": {
        "id": "nOU_hlVkVIP4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the the dataframe to run the predictions and classification on."
      ],
      "metadata": {
        "id": "OKb8S5wdfWYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " finaljeopardy= jeparody[['highval', 'finalform']].copy()"
      ],
      "metadata": {
        "id": "-_hBB5Z4VWcs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(finaljeopardy)"
      ],
      "metadata": {
        "id": "o1wRDpVAWAvz",
        "outputId": "65d16c6f-b30c-4db1-a035-3cca4e0248dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        highval                                          finalform\n",
            "0             0  'for last 8 year life galileo house arrest esp...\n",
            "1             0  'no 2 1912 olympian football star carlisle ind...\n",
            "2             0  'the city yuma state record average 4,055 hour...\n",
            "3             0  'in 1963 live `` art linkletter show company s...\n",
            "4             0  'signer dec. indep. framer constitution mass. ...\n",
            "...         ...                                                ...\n",
            "216924        1  'in 2006 cast long-running hit embarked < href...\n",
            "216925        1  'this puccini opera turn solution 3 riddle pos...\n",
            "216926        1  'in north america term properly applied 4 spec...\n",
            "216927        1  'in penny lane `` hellraiser grew barber shave...\n",
            "216928        1  'from ft. sill okla. made plea arizona land ho...\n",
            "\n",
            "[204903 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports sklearn to do the heavy lifting in analysis of the word patterns."
      ],
      "metadata": {
        "id": "Y0fUtu_XfhOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "olaBVdPtWYxs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assign the (x(q/a),y(value#) for the testing and training."
      ],
      "metadata": {
        "id": "371Qvb-BfzgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(finaljeopardy['finalform'], finaljeopardy['highval'], random_state=1)"
      ],
      "metadata": {
        "id": "0g3r2ELOW2Cn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert question and answer data into vectors for training and testing datasets"
      ],
      "metadata": {
        "id": "g4018WxcglmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
        "X_train_tf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tf = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "MnMaA_RvW6qe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the Niave Bayes classification training then run the test data to make predicitions."
      ],
      "metadata": {
        "id": "WP-cku1vhF6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train_tf, y_train)\n",
        "predictions = naive_bayes.predict(X_test_tf)"
      ],
      "metadata": {
        "id": "U6Q0o6OOX7p5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy of the predicitons to look at the words in the jeoparody questions/answers and determine the high low values.... better than flipping a coin but not a great parachute."
      ],
      "metadata": {
        "id": "2VJxffWThn6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Accuracy:', accuracy_score(y_test, predictions))"
      ],
      "metadata": {
        "id": "pVin8RVRYxqN",
        "outputId": "569a2673-94f6-4767-bbf6-ca5daba41503",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6157224846757506\n"
          ]
        }
      ]
    }
  ]
}